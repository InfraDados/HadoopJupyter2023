{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hive\n",
    "![Hive](https://hive.apache.org/images/hive_logo_medium.jpg)\n",
    "\n",
    "- https://hive.apache.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "- version 3.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Download package\n",
    "cd /opt/pkgs\n",
    "wget -q -c https://downloads.apache.org/hive/hive-3.1.2/apache-hive-3.1.2-bin.tar.gz\n",
    "\n",
    "# unpack file and create link\n",
    "tar -zxf apache-hive-3.1.2-bin.tar.gz -C /opt\n",
    "ln -s /opt/apache-hive-3.1.2-bin /opt/hive\n",
    "\n",
    "# update envvars.sh\n",
    "cat >> /opt/envvars.sh << EOF\n",
    "# Hive\n",
    "export HIVE_HOME=/opt/hive\n",
    "export PATH=\\${PATH}:\\${HIVE_HOME}/bin\n",
    "\n",
    "EOF\n",
    "\n",
    "# Fix guava and slf4j versions\n",
    "rm /opt/hive/lib/guava-19.0.jar\n",
    "cp /opt/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar /opt/hive/lib\n",
    "rm /opt/hive/lib/log4j-slf4j-impl-2.10.0.jar\n",
    "\n",
    "cat /opt/envvars.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "%load_ext dotenv\n",
    "%dotenv -o /opt/envvars.sh\n",
    "%env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hadoop configuration (for beeline)\n",
    "\n",
    "- core-site.xml\n",
    "\n",
    "```xml\n",
    "<configuration>\n",
    "...\n",
    "<property>\n",
    "  <name>hadoop.proxyuser.hadoop.groups</name>\n",
    "  <value>*</value>\n",
    "</property>\n",
    "<property>\n",
    "  <name>hadoop.proxyuser.hadoop.hosts</name>\n",
    "  <value>*</value>\n",
    "</property>\n",
    "</configuration>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hive Metastore\n",
    "\n",
    "- using local Derby database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create directory in HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "hdfs dfs -mkdir -p /user/hive/warehouse\n",
    "hdfs dfs -chmod g+w /user/hive/warehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir $HIVE_HOME/hiveserver2\n",
    "cd $HIVE_HOME/hiveserver2\n",
    "$HIVE_HOME/bin/schematool -dbType derby -initSchema 2> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start hiveserver2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd /opt/hive/hiveserver2\n",
    "nohup /opt/hive/bin/hive --service hiveserver2 \\\n",
    "--hiveconf hive.security.authorization.createtable.owner.grants=ALL \\\n",
    "--hiveconf hive.root.logger=INFO,console > hiveserver2.out 2>&1 &\n",
    "echo $! > hiveserver2.pid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "- SF Bay Area Bike Share (https://www.kaggle.com/benhamner/sf-bay-area-bike-share)\n",
    "- stations.csv and trips.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir /opt/datasets/bikeshare\n",
    "tar -zxf hivedataset.tgz -C /opt/datasets/bikeshare\n",
    "\n",
    "cd /opt/datasets/bikeshare\n",
    "ls\n",
    "\n",
    "hdfs dfs -mkdir -p bikeshare/stations\n",
    "hdfs dfs -put stations.csv bikeshare/stations\n",
    "hdfs dfs -mkdir -p bikeshare/trips\n",
    "hdfs dfs -put trips.csv bikeshare/trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect with beeline\n",
    "\n",
    "1. Run beeline\n",
    "\n",
    "```bash\n",
    "source /opt/envvars.sh\n",
    "beeline -n hadoop -u jdbc:hive2://localhost:10000\n",
    "```\n",
    "\n",
    "2. Configure jobs executor\n",
    "\n",
    "```sql\n",
    "SET hive.execution.engine=mr;\n",
    "SET mapreduce.framework.name=yarn;\n",
    "```\n",
    "\n",
    "3. Create bikeshare database\n",
    "\n",
    "```sql\n",
    "CREATE DATABASE bikeshare;\n",
    "SHOW DATABASES;\n",
    "USE bikeshare;\n",
    "```\n",
    "\n",
    "4. Create stations table\n",
    "\n",
    "```sql\n",
    "CREATE EXTERNAL TABLE stations (\n",
    "station_id INT,\n",
    "name STRING,\n",
    "lat DOUBLE,\n",
    "long DOUBLE,\n",
    "dockcount INT,\n",
    "landmark STRING,\n",
    "installation STRING\n",
    ")\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "LOCATION 'hdfs:///user/hadoop/bikeshare/stations';\n",
    "```\n",
    "\n",
    "5. Create trips table\n",
    "\n",
    "```sql\n",
    "CREATE EXTERNAL TABLE trips (\n",
    "trip_id INT,\n",
    "duration INT,\n",
    "start_date STRING,\n",
    "start_station STRING,\n",
    "start_terminal INT,\n",
    "end_date STRING,\n",
    "end_station STRING,\n",
    "end_terminal INT,\n",
    "bike_num INT,\n",
    "subscription_type STRING,\n",
    "zip_code STRING\n",
    ")\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "STORED AS TEXTFILE\n",
    "LOCATION 'hdfs:///user/hadoop/bikeshare/trips';\n",
    "```\n",
    "\n",
    "6. Show tables\n",
    "\n",
    "```sql\n",
    "SHOW TABLES;\n",
    "DESCRIBE stations;\n",
    "DESCRIBE trips;\n",
    "DESCRIBE FORMATTED stations;\n",
    "DESCRIBE FORMATTED trips;\n",
    "```\n",
    "\n",
    "7. Run query - number of trips per terminal\n",
    "\n",
    "```sql\n",
    "SELECT start_terminal, start_station, COUNT(1) AS count\n",
    "FROM trips\n",
    "GROUP BY start_terminal, start_station\n",
    "ORDER BY count\n",
    "DESC LIMIT 10;\n",
    "```\n",
    "\n",
    "8. Run query - join between stations and trips\n",
    "\n",
    "```sql\n",
    "SELECT t.trip_id, t.duration, t.start_date, s.name, s.lat, s.long, s.landmark\n",
    "FROM stations s\n",
    "JOIN trips t ON s.station_id = t.start_terminal\n",
    "LIMIT 10;\n",
    "```\n",
    "\n",
    "9. Exit beeline\n",
    "\n",
    "```sql\n",
    "!quit\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd /opt/hive/hiveserver2\n",
    "\n",
    "# kill hiveserver2\n",
    "kill $(cat hiveserver2.pid)\n",
    "rm hiveserver2.pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
