{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark\n",
    "![Spark](https://spark.apache.org/images/spark-logo-trademark.png)\n",
    "\n",
    "- https://spark.apache.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "- version 3.1.2 (Pre-built for Apache Hadoop 3.2 and later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Download package\n",
    "cd /opt/pkgs\n",
    "# wget -q -c https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz\n",
    "wget -q -c https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
    "\n",
    "# unpack file and create link\n",
    "tar -zxf spark-3.1.2-bin-hadoop3.2.tgz -C /opt\n",
    "ln -s /opt/spark-3.1.2-bin-hadoop3.2 /opt/spark\n",
    "\n",
    "# update envvars.sh\n",
    "cat >> /opt/envvars.sh << EOF\n",
    "# Spark\n",
    "export SPARK_HOME=/opt/spark\n",
    "export PYSPARK_PYTHON=python3\n",
    "export PYSPARK_DRIVER_PYTHON=python3\n",
    "export PYTHONIOENCODING=utf8\n",
    "export PATH=\\${PATH}:\\${SPARK_HOME}/bin\n",
    "\n",
    "EOF\n",
    "\n",
    "cat /opt/envvars.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "%load_ext dotenv\n",
    "%dotenv -o /opt/envvars.sh\n",
    "%env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Local execution\n",
    "#$SPARK_HOME/bin/run-example --master local SparkPi 10 2> /dev/null\n",
    "\n",
    "# Local execution with 4 processes\n",
    "#$SPARK_HOME/bin/run-example --master local[4] SparkPi 10\n",
    "\n",
    "# Execution using YARN\n",
    "# $SPARK_HOME/bin/run-example --master yarn SparkPi 10\n",
    "\n",
    "# Execution using spark-submit\n",
    "$SPARK_HOME/bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn \\\n",
    " $SPARK_HOME/examples/jars/spark-examples_2.12-3.1.2.jar 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pyspark\n",
    "\n",
    "```bash\n",
    "source /opt/envvars.sh\n",
    "pyspark --master yarn\n",
    "```\n",
    "\n",
    "- Spark application UI - http://localhost:4040\n",
    "\n",
    "```python\n",
    "text_file = sc.textFile(\"hdfs:///user/hadoop/shakespeare\")\n",
    "counts = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
    "             .map(lambda word: (word, 1)) \\\n",
    "             .reduceByKey(lambda a, b: a + b)\n",
    "counts.saveAsTextFile(\"hdfs:///user/hadoop/shakespeare_result\")\n",
    "counts.collect()\n",
    "```\n",
    "\n",
    "```python\n",
    "exit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pyspark-pictures\n",
    "\n",
    "- https://github.com/jkthompson/pyspark-pictures/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
