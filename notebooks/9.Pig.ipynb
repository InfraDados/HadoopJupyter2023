{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pig\n",
    "![Pig](https://pig.apache.org/images/pig-logo.gif)\n",
    "\n",
    "- https://pig.apache.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "- version 0.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Download package\n",
    "cd /opt/pkgs\n",
    "wget -q -c https://downloads.apache.org/pig/pig-0.17.0/pig-0.17.0.tar.gz\n",
    "\n",
    "# unpack file and create link\n",
    "tar -zxf pig-0.17.0.tar.gz -C /opt\n",
    "ln -s /opt/pig-0.17.0 /opt/pig\n",
    "\n",
    "# update envvars.sh\n",
    "cat >> /opt/envvars.sh << EOF\n",
    "# Pig\n",
    "export PIG_HOME=/opt/pig\n",
    "export PATH=\\${PATH}:\\${PIG_HOME}/bin\n",
    "\n",
    "EOF\n",
    "\n",
    "cat /opt/envvars.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "%load_ext dotenv\n",
    "%dotenv -o /opt/envvars.sh\n",
    "%env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd /opt/datasets\n",
    "wget -q -c https://tinyurl.com/y5roz8kz -O stations.csv\n",
    "hdfs dfs -mkdir stations\n",
    "hdfs dfs -put stations.csv stations\n",
    "hdfs dfs -head stations/stations.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grunt shell\n",
    "\n",
    "1. run in terminal (-x local => local execution)\n",
    "```\n",
    "source /opt/envvars.sh\n",
    "cd /opt/datasets\n",
    "pig -x local 2> /dev/null\n",
    "```\n",
    "2. \n",
    "```\n",
    "stations = LOAD 'stations.csv' USING PigStorage(',') AS \n",
    "(station_id:int, name:chararray, lat:float, long:float, \n",
    " dockcount:int, landmark:chararray, installation:chararray);\n",
    "```\n",
    "3. \n",
    "```\n",
    "station_ids_names = FOREACH stations GENERATE station_id, name;\n",
    "```\n",
    "4.\n",
    "```\n",
    "ordered = ORDER station_ids_names BY name;\n",
    "```\n",
    "\n",
    "5. \n",
    "```\n",
    "DESCRIBE stations;\n",
    "```\n",
    "6. \n",
    "```\n",
    "ILLUSTRATE ordered;\n",
    "```\n",
    "\n",
    "7. \n",
    "```\n",
    "DUMP ordered;\n",
    "```\n",
    "\n",
    "8. \n",
    "```\n",
    "QUIT;\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd /opt/src\n",
    "\n",
    "cat > list_stations.pig << EOF\n",
    "stations = LOAD 'stations' USING PigStorage(',') AS \n",
    "(station_id:int, name:chararray, lat:float, long:float, \n",
    " dockcount:int, landmark:chararray, installation:chararray);\n",
    "station_ids_names = FOREACH stations GENERATE station_id, name;\n",
    "ordered = ORDER station_ids_names BY name;\n",
    "STORE ordered INTO 'ordered';\n",
    "EOF\n",
    "\n",
    "# run using mapreduce\n",
    "pig -x mapreduce -f list_stations.pig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "hdfs dfs -cat ordered/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordCount using Pig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd /opt/datasets\n",
    "wget -q -c https://tinyurl.com/y68jxy7f -O stop-word-list.csv\n",
    "hdfs dfs -mkdir stopwords\n",
    "hdfs dfs -put stop-word-list.csv stopwords\n",
    "hdfs dfs -cat stopwords/stop-word-list.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run in grunt\n",
    "\n",
    "```\n",
    "source /opt/envvars.sh\n",
    "cd /opt/datasets\n",
    "pig -x mapreduce 2> /dev/null\n",
    "```\n",
    "\n",
    "```\n",
    "-- List HDFS content\n",
    "fs -ls\n",
    "fs -ls shakespeare\n",
    "\n",
    "-- Job name to appear in YARN\n",
    "SET job.name 'Word Count in Pig';\n",
    "\n",
    "-- Load shakespeare dataset\n",
    "shakespeare = LOAD 'shakespeare' AS (lineoftext:chararray);\n",
    "\n",
    "-- Load stopwords\n",
    "stopwords = LOAD 'stopwords' USING PigStorage() AS (stopword:chararray);\n",
    "\n",
    "-- Create bag of words\n",
    "words = FOREACH shakespeare GENERATE\n",
    "        FLATTEN(TOKENIZE(REPLACE(LOWER(TRIM(lineoftext)),\n",
    "        '[\\\\p{Punct},\\\\p{Cntrl}]',''))) AS word;\n",
    "\n",
    "-- Remove empty words\n",
    "realwords = FILTER words BY SIZE(word) > 0;\n",
    "\n",
    "-- Create bag of stop words\n",
    "flattened_stopwords = FOREACH stopwords GENERATE\n",
    "       FLATTEN(TOKENIZE(stopword)) AS stopword;\n",
    "\n",
    "-- Associate words with respective stop words\n",
    "right_joined = JOIN flattened_stopwords\n",
    "               BY stopword RIGHT OUTER,\n",
    "               realwords BY word;\n",
    "\n",
    "-- Remove stop words\n",
    "meaningful_words = FILTER right_joined BY\n",
    "          (flattened_stopwords::stopword IS NULL);\n",
    "\n",
    "-- Retrieve remaining words\n",
    "shakespeare_real_words = FOREACH meaningful_words\n",
    "          GENERATE realwords::word AS word;\n",
    "\n",
    "-- Group words\n",
    "grouped = GROUP shakespeare_real_words BY word;\n",
    "\n",
    "-- Count grouped words\n",
    "counted = FOREACH grouped GENERATE group AS word,\n",
    "          COUNT(shakespeare_real_words) AS wordcount;\n",
    "\n",
    "-- Sort bag in descending order\n",
    "ordered = ORDER counted BY wordcount DESC;\n",
    "\n",
    "-- Select 30 first words\n",
    "top30 = LIMIT ordered 30;\n",
    "\n",
    "-- Store output\n",
    "STORE top30 INTO 'shakespeare_top30';\n",
    "\n",
    "-- Show output from HDFS\n",
    "fs -cat shakespeare_top30/*\n",
    "\n",
    "-- Exit\n",
    "QUIT;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
